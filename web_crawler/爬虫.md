# 爬虫

| 题型 | 分值                |
| ---- | ------------------- |
| 选择 | 10 x 2分 = **20分** |
| 填空 | 10 x 1分 = **10分** |
| 判断 | 5 x 2 分 = **10分** |
| 问答 | 5 x 12分 = **60分** |

[TOC]



## 爬虫

### 工作原理	`p33`

爬虫的工作原理是通过**HTTP**来获取网页内容。

-   连接**DNS**域名服务器，将待抓取的**URL**进行域名解析
-   根据**HTTP**，发送**HTTP Request**和**Response**来获取网页内容



### 横向爬虫、纵向爬虫

-   **横向爬虫**

    是指在爬取的网站页面中，以“页”为单位，找寻该网站分页器规律。一页一页的爬取网站数据信息，大多数网站，采用分页管理模式，针对这类网站，首先要确立横向爬取方法。

-   **纵向爬虫**

    是指在一个页面内，按不同的“条目”为单位。找寻各条目之间的规律。一条一条的爬取一个网页中的数据信息。也就是同时爬取一个页面内不同类别数据。



### 反爬虫



### 验证码

#### 图形验证码

-   二值化
-   图片降噪
-   字符分割
-   特征匹配





## 网络

### http/https

**HTTP**使用统一资源标识符（Uniform Resource Identifiers, URI）来传输数据和建立连接。

-   **URI**
    -   Uniform Resource Identifier 统一资源**标识**符
    -   URI 是用来标示 一个具体的资源的，我们可以通过 URI 知道一个资源是什么。
-   **URL**
    -   Uniform Resource Location 统一资源**定位**符
    -   URL 则是用来定位具体的资源的，标示了一个具体的资源位置。互联网上的每个文件都有一个唯一的URL。



**HTTP**：是一个基于TCP/IP通信协议来传递数据的协议，传输的数据类型为HTML文件，图片文件，查询结果等

**HTTPS**：一般理解为HTTP+SSL/TLS，通过 SSL证书来验证服务器的身份，并为浏览器和服务器之间的通信进行加密



**总结HTTPS和HTTP的区别**

-   HTTPS是HTTP协议的安全版本，HTTP协议的数据传输是明文的，是不安全的，HTTPS使用了SSL/TLS协议进行了加密处理。
-   http和https使用连接方式不同，默认端口也不一样，http是80，https是443。





### IP地址



### status code（状态码）

**状态码分类**：

-   **1XX**

    信息型，服务器收到请求，需要请求者继续操作。

-   **2XX**

    成功型，请求成功收到，理解并处理。

-   **3XX**

    重定向，需要进一步的操作以完成请求。

-   **4XX**

    客户端错误，请求包含语法错误或无法完成请求。

-   **5XX**

    服务器错误，服务器在处理请求的过程中发生了错误。



**常见状态码**：

-   **100** - `Continue` - 初始状态请求已接受
-   **200** - `OK` - 客户端请求成功
-   **301** - `Moved Permanently` - 资源（网页等）被永久转移到其它URL
-   **302** - `Found` - 临时跳转
-   **400** - `Bad Request` - 客户端请求有语法错误，不能被服务器所理解
-   **401** - `Unauthorized `- 请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用
-   **404** - `Not Found` - 请求资源不存在，可能是输入了错误的URL
-   **500** - `Internal Server Error` - 服务器内部发生了不可预期的错误
-   **503** - `Server Unavailable` - 服务器当前不能处理客户端的请求，一段时间后可能恢复正常。



### cookie

类型为“**小型文本文件**”，是某些网站为了辨别用户身份，进行**Session**跟踪而储存在用户本地终端上的数据（通常经过加密），由**用户客户端**计算机暂时或永久保存的信息。

**cookie**由服务器产生，并发送回客户端保存。





### headers

模拟浏览器进行访问

**headers**是解决**requests**请求反爬的方法之一





### GET/POST

-   **GET** - 从指定的资源请求数据。
-   **POST** - 向指定的资源提交要被处理的数据。

#### get

用于获取数据，并且以数据完整性为前提

**工作流程**：

-   客户端向服务器发送**TCP**连接请求
-   服务器收到**TCP**连接请求后进行响应
-   客户端收到服务器的响应后，开始发送**GET**请求内容（数据报头、数据报内容）
-   服务器收到**GET**请求的数据，如果找到相应数据，则返回响应数据



#### post

**工作流程**：

-   客户端向服务器发送**TCP**连接请求
-   服务器收到**TCP**连接请求后进行响应
-   客户端收到服务器的响应后，开始发送**POST**请求内容（数据报头）
-   服务器收到**POST**请求头后，向客户端发送响应状态码`100 continue`表示可以接收**POST**的数据报内容
-   客户端收到服务器的响应状态码后，开始发送**POST**的数据报内容
-   服务器收到客户端的**POST**数据报内容后，处理成功后返回包括响应状态码`200 ok`在内的响应数据





### ajax

用于创建快速动态网页的技术





### URL格式





## python

### pip



### 字典



### pickle



### 字符串找子串



### tk



### csv读写

读

```python
import csv
file = 'xxx.csv'
with open(file, 'r', encoding='utf-8') as f:
    r = csv.reader(f)
	# 获取表格头部
    header = next(f)
```

写

```python
import csv
file = 'xxx.csv'
with open(file, 'r', encoding='utf-8') as f:
    w = csv.writer(f)
    wr.writerow(['内容1', '内容2',])
    wr.writerow(['内容1', '内容2',])
    wr.writerow(['内容1', '内容2',])
    wr.writerow(['内容1', '内容2',])
```





### requests、beautifulsoup



### 文件操作



### 随机数





## 其他

### api

是一些预先定义的接口（如函数、HTTP接口），或指软件系统软件系统/224122)不同组成部分衔接的约定



### mysql



### robots.txt